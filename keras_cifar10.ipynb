{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-cifar10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python391jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
      "display_name": "Python 3.9.1 64-bit"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/veronica-thesis/blob/master/keras_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqy8wi_uqbW"
      },
      "source": [
        "# Convolution Network\n",
        "\n",
        "Convolution Neural Networks (CNN) have been very successful especially when modeling images. In this notebook we introduce CNNs and use Keras to learn the CIFAR10 data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAWSu-88vYRO"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAFEhugJkuXt"
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models,layers\n",
        "from tensorflow.keras.utils import Sequence\n",
        "#from tensorflow.python.keras.utils import data_utils\n",
        "import math\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYohKtgX1MAY"
      },
      "source": [
        "### Convolution Operations\n",
        "We start with a simple example. Let I be an input image. Typically $I$ would be represented by a tensor of shape $(H,W,C)$ where $H$, $W$, and $C$ are the height, width, and color channel respectively. Therefore,  $I[h,w,c]$ refers to the value of channel $c$ in pixel $(h,w)$. Let $K$ be a filter with shape $(m,n)$ then the convolution operation produces the following tensor\n",
        "\\begin{align*}\n",
        "T_{i,j}=\\sum_c\\sum_{m,n}X_{i+m,j+n,c}*K_{m,n}\n",
        "\\end{align*}\n",
        "The above operation is illustrated in the example below. Click on the figures to see the sequence of operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDJ1ldS4DMLH"
      },
      "source": [
        "(img_train,label_train),(img_test,label_test)=tf.keras.datasets.cifar10.load_data()\n",
        "img_train=img_train/255.0\n",
        "img_test=img_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkPVJET7Ds6Y"
      },
      "source": [
        "print(\"img_train shape={},label_train shape={}\".format(img_train.shape,label_train.shape))\n",
        "print(\"img_test shape={},label_test shape={}\".format(img_test.shape,label_test.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pO1rl6OwCF7"
      },
      "source": [
        "We have dealt with this dataset before but it is helpful to recall some of its properties. As can be seen from the above the training data contains 50000 samples and test data contains 10000 samples. The labels are numbers from 0 to 9. Below we plot the first 10 images and their corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrdCVq5nwtwY"
      },
      "source": [
        "fig=plt.figure()\n",
        "fig.tight_layout()\n",
        "plt.subplots_adjust( wspace=1, hspace=1)\n",
        "\n",
        "for i in range(0,10):\n",
        "    img=img_train[i]    \n",
        "    t=fig.add_subplot(2,5,i+1)\n",
        "    t.set_title(str(label_train[i]))\n",
        "    t.axes.get_xaxis().set_visible(False)\n",
        "    t.axes.get_yaxis().set_visible(False)\n",
        "    plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxnPOQFVGcX4"
      },
      "source": [
        "# Model\n",
        "\n",
        "One can think of the input and output of convolution layers as **boxes** of the form (width,height,depth). Usually the depth of the input is the number of variables used for colors e.g. 3. The output of a Conv2D of nfilters of size (x,y) is (width-x+1, height-y+1,nfilters) where we have assumed that the stride is 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lClgW_GYH42o"
      },
      "source": [
        "def createModel():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3),  activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10,activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbrJYUhSEu_z"
      },
      "source": [
        "model=createModel()\n",
        "#tf.keras.utils.plot_model(model,show_shapes=True)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYUxWKQr6Kjl"
      },
      "source": [
        "## Optimization\n",
        "\n",
        "Keras can use many optimization method. In this notebook we use the __Adam__ method which can be described loosely as __adaptive__ gradient descent.\n",
        "\n",
        "Also since the labels are __NOT__ in one_hot_encoding we use the \"Sparse\" version of the crossentropy loss: __SparseCategoricalCrossentropy__. Finally, if we don't specify from_logits=False then the loss function would compute softwmax before computing the loss. Since we are computing softwmax in our model already we turn this step off by specifying from_logits=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DbRaKJKFvug"
      },
      "source": [
        "# if we don't use softmax in the last layer, i.e. if the output of the\n",
        "# model is NOT probabilities then use from_logits=True\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(img_train,label_train, batch_size=128,epochs=10, \n",
        "                   validation_data=(img_test, label_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLe-ndQpqbPj"
      },
      "source": [
        "### Testing the Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuvWaksuYAKi"
      },
      "source": [
        "_,test_accuracy=model.evaluate(img_test,label_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip0XKsOUkuX3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGa1LVGPkuX3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}